import torch
import joblib
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import pandas as pd
import psycopg2
import os
from sklearn.preprocessing import StandardScaler
from dotenv import load_dotenv

# [1] ê²½ë¡œ ë° í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
current_file_path = os.path.abspath(__file__)
training_dir = os.path.dirname(current_file_path)
event_ai_dir = os.path.dirname(training_dir)
aria_root = os.path.dirname(os.path.dirname(event_ai_dir))

dotenv_path = os.path.join(aria_root, ".env")
load_dotenv(dotenv_path)

def load_advanced_data():
    conn = psycopg2.connect(
        host=os.getenv("DB_HOST", "db"),
        database=os.getenv("DB_NAME", "aria"),
        user=os.getenv("DB_USER", "user"),
        password=os.getenv("DB_PASSWORD", "1234"),
        port=os.getenv("DB_PORT", "5432")
    )
    
    # [ìˆ˜ì • í¬ì¸íŠ¸] ë¡œê·¸ë¥¼ ë‹¨ìˆœíˆ JOINí•˜ì§€ ì•Šê³ , ì„¸ì…˜ë³„ë¡œ í‰ê· ê°’ì„ ë‚´ì„œ 1ì¤„ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.
    # ì´ë ‡ê²Œ í•´ì•¼ 18,000ê°œì˜ ì¤‘ë³µì´ ì‚¬ë¼ì§€ê³  ì§„ì§œ 100ê°œì˜ í•™ìŠµ ë°ì´í„°ê°€ ë©ë‹ˆë‹¤.
    query = """
        SELECT 
            AVG(l.temperature) as temperature, 
            AVG(l.humidity) as humidity, 
            AVG(l.pm25) as pm25, 
            AVG(l.voc) as voc, 
            s.pm25_slope, s.temp_hum_corr, s.pm_voc_corr, 
            s.pm25_std, s.voc_std, s.pm25_range,
            s.final_label
        FROM sensor_sessions s
        JOIN sensor_data_logs l ON s.session_id = l.session_id
        GROUP BY s.session_id
    """
    df = pd.read_sql(query, conn)
    conn.close()
    return df

# [2] ì‹ ê²½ë§ ëª¨ë¸ ì •ì˜ (ì„±êµ­ë‹˜ì˜ êµ¬ì¡° ìœ ì§€)
class AdvancedCookingDetector(nn.Module):
    def __init__(self):
        super(AdvancedCookingDetector, self).__init__()
        self.layer = nn.Sequential(
            nn.Linear(10, 32),
            nn.ReLU(),
            nn.Linear(32, 16),
            nn.ReLU(),
            nn.Linear(16, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.layer(x)

def train_advanced():
    # GPU(GTX 1650) ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ ì²´í¬
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ í•™ìŠµ ì¥ì¹˜: {device} (10ê°œ íŠ¹ì„± í™œìš©)")

    df = load_advanced_data()
    feature_cols = [
        'temperature', 'humidity', 'pm25', 'voc',
        'pm25_slope', 'temp_hum_corr', 'pm_voc_corr', 
        'pm25_std', 'voc_std', 'pm25_range'
    ]
    
    X = df[feature_cols].values
    y = df['final_label'].values.reshape(-1, 1)
    
    print(f"ğŸ“Š ì‹¤ì œ í•™ìŠµ ì„¸ì…˜ ê°œìˆ˜: {len(df)}ê°œ")
    if len(df) < 10:
        print("âš ï¸ ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. augmenter.pyì—ì„œ multiply ê°’ì„ í‚¤ì›Œì£¼ì„¸ìš”.")

    # ë°ì´í„° ì •ê·œí™”
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # í…ì„œ ë³€í™˜
    X_tensor = torch.FloatTensor(X_scaled).to(device)
    y_tensor = torch.FloatTensor(y).to(device)
    dataset = TensorDataset(X_tensor, y_tensor)
    loader = DataLoader(dataset, batch_size=min(32, len(df)), shuffle=True)

    # ëª¨ë¸ ì´ˆê¸°í™”
    model = AdvancedCookingDetector().to(device)
    criterion = nn.BCELoss()
    # í•™ìŠµë¥ ì„ 0.01ì—ì„œ 0.001ë¡œ ë‚®ì¶° ë” ì„¸ë°€í•˜ê²Œ í•™ìŠµí•˜ë„ë¡ ì¡°ì •
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    print("ğŸ“ˆ ê³ ë„í™”ëœ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    model.train()
    for epoch in range(25): # ì¡°ê¸ˆ ë” ì„¸ë°€í•˜ê²Œ 25íšŒ í•™ìŠµ
        total_loss = 0
        for batch_X, batch_y in loader:
            optimizer.zero_grad()
            outputs = model(batch_X)
            loss = criterion(outputs, batch_y)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        
        if (epoch + 1) % 5 == 0:
            print(f"Epoch {epoch+1}/25, Loss: {total_loss/len(loader):.6f}")

    # [3] ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
    models_dir = os.path.join(event_ai_dir, "models")
    if not os.path.exists(models_dir):
        os.makedirs(models_dir)

    model_path = os.path.join(models_dir, "event_model.pt")
    scaler_path = os.path.join(models_dir, "scaler.pkl")

    torch.save(model.state_dict(), model_path)
    joblib.dump(scaler, scaler_path)
    
    print("\n" + "="*50)
    print(f"âœ… í•™ìŠµ ì™„ë£Œ! ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ê°±ì‹ ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ì €ì¥ ê²½ë¡œ: {model_path}")
    print("="*50)

if __name__ == "__main__":
    train_advanced()