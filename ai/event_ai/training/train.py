import torch
import joblib
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import pandas as pd
import psycopg2
import os
from sklearn.preprocessing import StandardScaler
from dotenv import load_dotenv

# [1] ê²½ë¡œ ì„¤ì • ìµœì í™”
# í˜„ì¬ íŒŒì¼ ìœ„ì¹˜: aria/ai/event_ai/training/train.py
current_file_path = os.path.abspath(__file__)
training_dir = os.path.dirname(current_file_path)   # training/
event_ai_dir = os.path.dirname(training_dir)       # event_ai/
ai_dir = os.path.dirname(event_ai_dir)             # ai/
aria_root = os.path.dirname(ai_dir)                # aria/

# aria/.env íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ DB ì ‘ì† ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤
dotenv_path = os.path.join(aria_root, ".env")
load_dotenv(dotenv_path)

# [2] ë©”íƒ€ë°ì´í„°ì™€ ë¡œê·¸ë¥¼ ì¡°ì¸í•˜ì—¬ ë¡œë“œ
def load_advanced_data():
    conn = psycopg2.connect(
        host=os.getenv("DB_HOST", "db"),
        database=os.getenv("DB_NAME", "aria"),
        user=os.getenv("DB_USER", "user"),
        password=os.getenv("DB_PASSWORD"),
        port=os.getenv("DB_PORT", "5432")
    )
    query = """
        SELECT 
            l.temperature, l.humidity, l.pm25, l.voc, 
            s.pm25_slope, s.temp_hum_corr, s.pm_voc_corr, 
            s.pm25_std, s.voc_std, s.pm25_range,
            s.final_label
        FROM sensor_data_logs l
        JOIN sensor_sessions s ON l.session_id = s.session_id
    """
    df = pd.read_sql(query, conn)
    conn.close()
    return df

# [3] ì‹ ê²½ë§ ëª¨ë¸ ì •ì˜
class AdvancedCookingDetector(nn.Module):
    def __init__(self):
        super(AdvancedCookingDetector, self).__init__()
        self.layer = nn.Sequential(
            nn.Linear(10, 32), # 4(ê¸°ë³¸) + 6(ë©”íƒ€) = 10
            nn.ReLU(),
            nn.Linear(32, 16),
            nn.ReLU(),
            nn.Linear(16, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.layer(x)

def train_advanced():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"í•™ìŠµ ì¥ì¹˜: {device} (10ê°œ íŠ¹ì„± í™œìš©)")

    df = load_advanced_data()
    feature_cols = [
        'temperature', 'humidity', 'pm25', 'voc',
        'pm25_slope', 'temp_hum_corr', 'pm_voc_corr', 
        'pm25_std', 'voc_std', 'pm25_range'
    ]
    X = df[feature_cols].values
    y = df['final_label'].values.reshape(-1, 1)

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    X_tensor = torch.FloatTensor(X_scaled).to(device)
    y_tensor = torch.FloatTensor(y).to(device)
    dataset = TensorDataset(X_tensor, y_tensor)
    loader = DataLoader(dataset, batch_size=32, shuffle=True)

    model = AdvancedCookingDetector().to(device)
    criterion = nn.BCELoss()
    optimizer = optim.Adam(model.parameters(), lr=0.01)

    print("ğŸ“ˆ ê³ ë„í™”ëœ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    model.train()
    for epoch in range(15):
        total_loss = 0
        for batch_X, batch_y in loader:
            optimizer.zero_grad()
            outputs = model(batch_X)
            loss = criterion(outputs, batch_y)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/15, Loss: {total_loss/len(loader):.4f}")

    # [4] ëª¨ë¸ ì €ì¥ ê²½ë¡œ ìˆ˜ì • (models/ í´ë” ë‚´ ì €ì¥)
    # training/ í´ë”ì—ì„œ í•œ ë‹¨ê³„ ìœ„ì¸ event_ai/models/ í´ë”ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.
    models_dir = os.path.join(event_ai_dir, "models")
    if not os.path.exists(models_dir):
        os.makedirs(models_dir)

    model_path = os.path.join(models_dir, "event_model.pt")
    scaler_path = os.path.join(models_dir, "scaler.pkl")

    torch.save(model.state_dict(), model_path)
    joblib.dump(scaler, scaler_path)
    
    print("\n" + "="*50)
    print(f"í•™ìŠµ ì™„ë£Œ ë° ëª¨ë¸ ì €ì¥ ì„±ê³µ!")
    print(f"ëª¨ë¸: {model_path}")
    print(f"ìŠ¤ì¼€ì¼ëŸ¬: {scaler_path}")
    print("="*50)

if __name__ == "__main__":
    train_advanced()