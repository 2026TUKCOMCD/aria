# 🔄 ARIA_Sync (Data Pipeline & MLOps Infrastructure)

이 디렉토리는 ARIA 로봇으로부터 수집된 S3 데이터 레이크를 로컬 GPU 서버와 동기화하고, 학습 전 데이터 무결성을 검사하는 자동화 파이프라인을 포함합니다.

## 🛠 주요 구성 파일
- `sync_data.bat`: S3 동기화 및 데이터 클렌징을 한 번에 실행하는 배치 파일
- `data_cleaner.py`: 다운로드된 JSON 데이터의 무결성 및 이상치 필터링 (C5-1)
- `data_lake/`: S3에서 내려받은 원본 JSON 로그 데이터 (Git 제외)
- `valid_manifest.json`: 무결성 검사를 통과한 학습 가능 파일 리스트

---

## 🕒 Windows 작업 스케줄러 자동화 설정 가이드

데이터 파이프라인의 자동화를 위해 아래와 같이 'Windows 작업 스케줄러' 설정을 권장합니다.

### 1. 기본 작업 만들기
- **이름**: `ARIA_S3_Data_Sync`
- **트리거**: `매일 (Daily)` / `오전 12:00:00` (밤 12시)

### 2. 동작 설정 (가장 중요)
- **동작**: `프로그램 시작`
- **프로그램/스크립트**: 
  `C:\aria\ai\event_ai\ARIA_Sync\sync_data.bat`
- **시작 위치(옵션)**: 
  `C:\aria\ai\event_ai\ARIA_Sync` 
  *(※ 주의: 이 칸을 비워두면 경로를 찾지 못해 에러가 발생합니다.)*

### 3. 추가 조건 설정
- **조건**: '컴퓨터의 교류 전원이 연결된 경우에만 작업 시작' 해제 (노트북 사용 시 권장)
- **설정**: '요청 시 작업이 실행되도록 허용' 체크 (수동 테스트용)

---

## 🧹 데이터 무결성 검사 기준 (C5-1)
`data_cleaner.py`는 아래 기준에 따라 학습 데이터를 선별합니다:
1. **데이터 개수**: 30분 세션당 최소 800개 이상의 로그 존재 여부
2. **이상치 필터링**: 
   - PM2.5 > 3000 (센서 오류로 간주)
   - VOC > 1000 (센서 포화로 간주)
3. **Key 구조**: `raw_logs` 및 `meta.stats` 키 존재 여부 확인